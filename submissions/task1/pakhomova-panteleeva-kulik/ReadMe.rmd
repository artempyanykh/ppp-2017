---
title: "ReadME"
author: "Pakhomova, Panteleeva, Kulik"
date: '9 апреля 2017 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#### **ПОСТАНОВКА И ВЫПОЛНЕНИЕ ЗАДАНИЯ**

В рамках первого задания практикума необходимо провести анализ
временного ряда и попробовать предсказать значения для последующих
месяцев.

Были выполнены все **три пункта задания**:

* * * * *

1.  *Проверка тренировочного ряда на стационарность одним из двух
    способов:*

    1.  *Визуальная оценка:*

        *Исследовать графики ряда, скользящей статистики (среднего,
        стандартного отклонения)*

    2.  *Тест Дики-Фуллера*

* * * * *

**Метод решения:**

В начале программы подключаются необходимые библиотеки:

```{r load_packages, include=FALSE}
library(xts)
library(TTR)
library(MLmetrics)
library(forecast)

# Changing work directory, reading training and testing data
setwd("C:/Users/Anastasia Panteleeva/Desktop/Task1")
```

Для исследования тренировочного ряда на стационарность использовался
первый способ визуальной оценки.

С помощью функции `SMA()` строим скользящее среднее ряда с интервалом 5.
Строим стандартное отклонение исходного временного ряда от его
скользящего среднего (по формуле: значения исходного временного ряда –
значения его скользящего среднего арифметического).

При визуализации на графике всех полученных временных рядов (исходного,
скользящего среднего и отклонения) был сделан вывод о нестационарности
исходного ряда:

```{r train, echo=FALSE}
data <- read.csv(file = "training.csv", header = TRUE)
train <- xts(as.matrix(data[,2]), as.Date(strptime(data[,1], "%Y-%m-%d")))
ts_train <- ts(as.matrix(data[,2]), frequency=12, start=c(1959,1))
data <- read.csv(file = "testing.csv", header = TRUE)
test <- xts(as.matrix(data[,2]), as.Date(strptime(data[,1], "%Y-%m-%d")))
ts_test <- ts(as.matrix(data[,2]), frequency=12, start=c(1989,1))

# Plot of time series
plot.xts(train)

# Moving average
z1 <- SMA(train, 5)
lines(z1, col="red")

# Standard deviation
lines(train - z1 + 40, col="blue")
```


* * * * *

*2. Разложение временного ряда на тренд, сезонность и остаток в
соответствии с аддитивной и мультипликативной моделями. Полученные
результаты визуализировать на графике и оценить стационарность.*

* * * * *

**Метод решения:**

Для разложения временного ряда использовалась функция `decompose()` для
случая аддитивной и мультипликативной модели, в результате чего получили
четыре графика: наблюдаемый, тренд, сезонность и остаток.

По полученной визуализации делаем выводы о стационарности рядов:
наблюдаемый ряд и тренд являются нестационарными рядами, в то время как
сезонность и остаток – стационарны:

```{r, echo=FALSE}
# Trend, seasonal, random, observed
de <- decompose(ts_train, type = "additive")
plot(de)
de <- decompose(ts_train, type = "multiplicative")
plot(de)
```


* * * * *

*3. Проверка полученного ряда на интегрируемость порядка k.* *В случае
интегрированности ряда применить к нему модель ARIMA с коэффициентами,
полученными применением функции автокорреляции и функции частичной
автокорреляции. Для нескольких моделей предсказать значения тестовой
выборки, визуализировать их, посчитать r2 score для каждой из моделей. С
помощью информационного метода Акаике произвести отбор наилучшей модели
и провести анализ полученных результатов.*

* * * * *

**Метод решения:**

Для реализации этого пункта задания использовалась дополнительные
библиотеки `forecast` и `MLmetrics`.

Ряд называется интегрируемым, если ряд его разностей – стационарен.

Сначала находится число разностей, достаточное для того, чтобы ряд
разностей был стационарен. Это число также является порядком
интегрируемости. Для нахождения этого числа к тренировочному ряду
применяем функцию `ndiffs()` и получаем значение равное единице. Таким
образом, по определению, исходный тренировочный ряд является
интегрируемым с порядком интегрируемости равным 1.

```{r, echo=FALSE}
# Order of integration
int <- ndiffs(train)
```


Находим ряд разностей исходного тренировочного ряда с помощью функции
`diff()` и полученного на предыдущем шаге порядка интегрируемости. В
силу определения порядка интегрируемости полученный ряд разностей
является стационарным.

```{r, echo=FALSE}
# The first difference
di <- diff(ts_train, differences = 1)
```

Для нахождения коэффициента **q** модели ARIMA к полученному ряду
разностей применяем функцию автокорреляции `acf()`, визуализируем
полученный результат на графике и анализируем его: - Нумеруем полученные
лаги слева направо от 0 и далее - Фиксируем номер первого лага,
попадающего в границы значимости - Значение коэффициента q = номер лага,
полученного на предыдущем шаге – 1.

```{r, echo=FALSE}
# Auto- and cross- covariance and -correlation 
acf(di, main = 'ACF for Differenced Series') # q = 4
```


Аналогичным образом находим коэффициент **p** применением функции
частичной автокорреляции `pacf()`, визуализируем полученный результат на
графике и анализируем его аналогичным коэффициенту q образом, но нумеруя
лаги начиная с 1.

```{r, echo=FALSE}
pacf(di, main = 'PACF for Differenced Series') # p = 2
```


В результате имеем все три коэффициента модели ARIMA: p = 2, q = 4, d =
1 (порядок интегрируемости временного ряда).

К тестовому временному ряду трижды применяем модель ARIMA с различными
значениями коэффициентов:

-   ARIMA(2, 1, 0)
-   ARIMA(0, 1, 4)
-   ARIMA(2, 1, 4)

В результате чего получаем три модели. Для каждой из них строим прогноз, используя функцию `forecast.ARIMA()` и находим коэффициент детерминации (r2 score) с помощью функции `R2_Score()`. Коэффициент детерминации прогноза каждой модели ARIMA должен быть достаточно близок к нулю, таким образом проверяется достоверность прогноза.

- Для ARIMA(2, 1, 0):

```{r, echo=FALSE}
# Three different models
model_1 <- arima(ts_train, order = c(2,1,0))
fr_1 <- forecast.Arima(model_1, h = 60)
r_1 <- R2_Score(y_true = ts_test, y_pred = fr_1$mean)
r_1
```

- Для ARIMA(0, 1, 4):

```{r, echo=FALSE}
model_2 <- arima(ts_train, order = c(0,1,4))
fr_2 <- forecast.Arima(model_2, h = 60)
r_2 <- R2_Score(y_true = ts_test, y_pred = fr_2$mean)
r_2
```

- Для ARIMA(2, 1, 4):

```{r, echo=FALSE}
model_3 <- arima(ts_train, order = c(2,1,4))
fr_3 <- forecast.Arima(model_3, h = 60)
r_3 <- R2_Score(y_true = ts_test, y_pred = fr_3$mean)
r_3
```


Далее, для нахождения наилучшей модели применяем информационный критерий Акаике
с помощью функции `AIC()`. Считается, что наилучшей является модель с
наименьшим значением критерия AIC. В нашем случае лучшие результаты дала
модель ARIMA(0, 1, 4):

```{r, echo=FALSE}
# Akaike's criterion
AIC(model_1, model_2, model_3) # model_2
```


Визуализируем результат прогноза наилучшей модели и накладываем на него
фактические (тренировочные) данные временного ряда. Анализируя график,
видим, что фактические данные не выходят за пределы спрогнозированной
области, из чего делаем вывод, что прогноз дал правильные результаты. Однако, предсказанные ей значения являются практически прямой линией, из чего можно сделать вывод, что прогноз не является точным. Особенно разницу между прогнозом и фактическими данными из `ts_test` можно увидеть на графике:

```{r, echo=FALSE}
# Testing and prediction
plot.forecast(fr_2)
lines(ts_test, col = 'red')
```


* * * * *

#### **ИНСТРУКЦИЯ ПО ЗАПУСКУ**

Для запуска программы необходимо установить RStudio и установить
необходимые библиотеки:

`install.packages(“xts”)`

`install.packages(“forecast”)`

`install.packages(“MLmetrics”)`

`library(TTR)`

* * * * *

#### **СПИСОК УЧАСТНИКОВ ГРУППЫ**

-   Пахомова Маргарита, группа 411 *– написание кода, сдача проекта в GitHub*
-   Кулик Артём, группа 411 *– написание кода*
-   Пантелеева Анастасия, группа 411 *– написание ReadMe*
